{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Experiments based on section 4.1  of arXiv:1808.00508 paper: Simple Function Learning Tasks(static task)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from NALU import NALU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_shape = (5000,100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_examples = x_shape[0]\n",
    "train_columns  = x_shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.random.rand(train_examples,train_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_x = np.random.rand(train_examples,train_columns)*10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Partition the inputs(consistently) to create \"a\" and \"b\"\n",
    "* The paper does not describe if \"a\" and \"b\" are mutually exclusive or not, will have to experiment\n",
    "* In the paper its not clear if for every experiment you  mix (+,-,*,/)   for calculating \"y\", let's experiment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Mutually exclusive(first half is a, second half is b)  and only use \"+\" for calculating \"y\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "partition_index = int(train_columns/2) #half colmns for a,half columns for b\n",
    "\n",
    "a = np.sum(x[:,:partition_index],axis=1)\n",
    "b = np.sum( x[:,partition_index:],axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_a = np.sum(test_x[:,:partition_index],axis=1)\n",
    "test_b = np.sum(test_x[:,partition_index:],axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Let's start simple:  y = a + b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y = a + b\n",
    "y = np.expand_dims(y,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_y = test_a + test_b\n",
    "test_y = np.expand_dims(test_y,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "EPOCHS = 10000\n",
    "PRINT_EVERY = 20\n",
    "LEARNING_RATE = 0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hello NALU world nalu1\n",
      "hello NALU world nalu2\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "\n",
    "\n",
    "X = tf.placeholder(tf.float32,shape = [train_examples,train_columns])\n",
    "Y = tf.placeholder(tf.float32,shape=[train_examples,1])\n",
    "\n",
    "nalu1 = NALU(input_shape=(train_examples,train_columns),size = 2,name = \"nalu1\")\n",
    "nalu1_output = nalu1.NALU_output(X)\n",
    "        \n",
    "nalu2 = NALU(input_shape=(train_examples,2),size=1,name = \"nalu2\")\n",
    "nalu2_output = nalu2.NALU_output(nalu1_output)\n",
    "        \n",
    "loss = tf.losses.mean_squared_error(nalu2_output,Y)\n",
    "adam_optimize = tf.train.AdamOptimizer(learning_rate=LEARNING_RATE).minimize(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 loss 2535.69873046875\n",
      "Epoch 20 loss 2559.358154296875\n",
      "Epoch 40 loss 2460.43798828125\n",
      "Epoch 60 loss 2388.0107421875\n",
      "Epoch 80 loss 2202.802001953125\n",
      "Epoch 100 loss 804.31787109375\n",
      "Epoch 120 loss 434.6862487792969\n",
      "Epoch 140 loss 249.3738250732422\n",
      "Epoch 160 loss 164.7243194580078\n",
      "Epoch 180 loss 115.90666198730469\n",
      "Epoch 200 loss 85.04906463623047\n",
      "Epoch 220 loss 65.90021514892578\n",
      "Epoch 240 loss 53.9377555847168\n",
      "Epoch 260 loss 46.3968391418457\n",
      "Epoch 280 loss 41.56233596801758\n",
      "Epoch 300 loss 38.38157272338867\n",
      "Epoch 320 loss 36.2103385925293\n",
      "Epoch 340 loss 34.656028747558594\n",
      "Epoch 360 loss 33.48018264770508\n",
      "Epoch 380 loss 32.538482666015625\n",
      "Epoch 400 loss 31.743755340576172\n",
      "Epoch 420 loss 31.04343032836914\n",
      "Epoch 440 loss 30.405813217163086\n",
      "Epoch 460 loss 29.811771392822266\n",
      "Epoch 480 loss 29.24970054626465\n",
      "Epoch 500 loss 28.712493896484375\n",
      "Epoch 520 loss 28.19573211669922\n",
      "Epoch 540 loss 27.696603775024414\n",
      "Epoch 560 loss 27.21324348449707\n",
      "Epoch 580 loss 26.74437141418457\n",
      "Epoch 600 loss 26.28904151916504\n",
      "Epoch 620 loss 25.846511840820312\n",
      "Epoch 640 loss 25.41620635986328\n",
      "Epoch 660 loss 24.99760627746582\n",
      "Epoch 680 loss 24.59025764465332\n",
      "Epoch 700 loss 24.193761825561523\n",
      "Epoch 720 loss 23.807750701904297\n",
      "Epoch 740 loss 23.431886672973633\n",
      "Epoch 760 loss 23.065832138061523\n",
      "Epoch 780 loss 22.709300994873047\n",
      "Epoch 800 loss 22.361997604370117\n",
      "Epoch 820 loss 22.023658752441406\n",
      "Epoch 840 loss 21.694013595581055\n",
      "Epoch 860 loss 21.37281608581543\n",
      "Epoch 880 loss 21.059825897216797\n",
      "Epoch 900 loss 20.75480842590332\n",
      "Epoch 920 loss 20.45753288269043\n",
      "Epoch 940 loss 20.16777801513672\n",
      "Epoch 960 loss 19.88532257080078\n",
      "Epoch 980 loss 19.609947204589844\n",
      "Epoch 1000 loss 19.341445922851562\n",
      "Epoch 1020 loss 19.07960319519043\n",
      "Epoch 1040 loss 18.824209213256836\n",
      "Epoch 1060 loss 18.575056076049805\n",
      "Epoch 1080 loss 18.33194923400879\n",
      "Epoch 1100 loss 18.094684600830078\n",
      "Epoch 1120 loss 17.863052368164062\n",
      "Epoch 1140 loss 17.636871337890625\n",
      "Epoch 1160 loss 17.41593360900879\n",
      "Epoch 1180 loss 17.20005989074707\n",
      "Epoch 1200 loss 16.98906135559082\n",
      "Epoch 1220 loss 16.782747268676758\n",
      "Epoch 1240 loss 16.58094024658203\n",
      "Epoch 1260 loss 16.383464813232422\n",
      "Epoch 1280 loss 16.190153121948242\n",
      "Epoch 1300 loss 16.000839233398438\n",
      "Epoch 1320 loss 15.81535816192627\n",
      "Epoch 1340 loss 15.633551597595215\n",
      "Epoch 1360 loss 15.45527458190918\n",
      "Epoch 1380 loss 15.280384063720703\n",
      "Epoch 1400 loss 15.10874080657959\n",
      "Epoch 1420 loss 14.940206527709961\n",
      "Epoch 1440 loss 14.77467155456543\n",
      "Epoch 1460 loss 14.612009048461914\n",
      "Epoch 1480 loss 14.452116012573242\n",
      "Epoch 1500 loss 14.29488468170166\n",
      "Epoch 1520 loss 14.140226364135742\n",
      "Epoch 1540 loss 13.988054275512695\n",
      "Epoch 1560 loss 13.83829402923584\n",
      "Epoch 1580 loss 13.690876960754395\n",
      "Epoch 1600 loss 13.54574203491211\n",
      "Epoch 1620 loss 13.402843475341797\n",
      "Epoch 1640 loss 13.262137413024902\n",
      "Epoch 1660 loss 13.123595237731934\n",
      "Epoch 1680 loss 12.987192153930664\n",
      "Epoch 1700 loss 12.852912902832031\n",
      "Epoch 1720 loss 12.720746994018555\n",
      "Epoch 1740 loss 12.590693473815918\n",
      "Epoch 1760 loss 12.462763786315918\n",
      "Epoch 1780 loss 12.336959838867188\n",
      "Epoch 1800 loss 12.213295936584473\n",
      "Epoch 1820 loss 12.091782569885254\n",
      "Epoch 1840 loss 11.972434043884277\n",
      "Epoch 1860 loss 11.855262756347656\n",
      "Epoch 1880 loss 11.740270614624023\n",
      "Epoch 1900 loss 11.627456665039062\n",
      "Epoch 1920 loss 11.516817092895508\n",
      "Epoch 1940 loss 11.40832805633545\n",
      "Epoch 1960 loss 11.301958084106445\n",
      "Epoch 1980 loss 11.197670936584473\n",
      "Epoch 2000 loss 11.09540843963623\n",
      "Epoch 2020 loss 10.99510669708252\n",
      "Epoch 2040 loss 10.896692276000977\n",
      "Epoch 2060 loss 10.800060272216797\n",
      "Epoch 2080 loss 10.70512866973877\n",
      "Epoch 2100 loss 10.611771583557129\n",
      "Epoch 2120 loss 10.519879341125488\n",
      "Epoch 2140 loss 10.429315567016602\n",
      "Epoch 2160 loss 10.339950561523438\n",
      "Epoch 2180 loss 10.251644134521484\n",
      "Epoch 2200 loss 10.164251327514648\n",
      "Epoch 2220 loss 10.077619552612305\n",
      "Epoch 2240 loss 9.991610527038574\n",
      "Epoch 2260 loss 9.906078338623047\n",
      "Epoch 2280 loss 9.820876121520996\n",
      "Epoch 2300 loss 9.73587703704834\n",
      "Epoch 2320 loss 9.65096378326416\n",
      "Epoch 2340 loss 9.566031455993652\n",
      "Epoch 2360 loss 9.480995178222656\n",
      "Epoch 2380 loss 9.395807266235352\n",
      "Epoch 2400 loss 9.310443878173828\n",
      "Epoch 2420 loss 9.224918365478516\n",
      "Epoch 2440 loss 9.139283180236816\n",
      "Epoch 2460 loss 9.053637504577637\n",
      "Epoch 2480 loss 8.96811294555664\n",
      "Epoch 2500 loss 8.882878303527832\n",
      "Epoch 2520 loss 8.798126220703125\n",
      "Epoch 2540 loss 8.714078903198242\n",
      "Epoch 2560 loss 8.630949974060059\n",
      "Epoch 2580 loss 8.54895305633545\n",
      "Epoch 2600 loss 8.468289375305176\n",
      "Epoch 2620 loss 8.389127731323242\n",
      "Epoch 2640 loss 8.311619758605957\n",
      "Epoch 2660 loss 8.235870361328125\n",
      "Epoch 2680 loss 8.161954879760742\n",
      "Epoch 2700 loss 8.089924812316895\n",
      "Epoch 2720 loss 8.019783973693848\n",
      "Epoch 2740 loss 7.951531410217285\n",
      "Epoch 2760 loss 7.88512659072876\n",
      "Epoch 2780 loss 7.820516586303711\n",
      "Epoch 2800 loss 7.75764274597168\n",
      "Epoch 2820 loss 7.6964287757873535\n",
      "Epoch 2840 loss 7.636799335479736\n",
      "Epoch 2860 loss 7.578656196594238\n",
      "Epoch 2880 loss 7.521924018859863\n",
      "Epoch 2900 loss 7.466512680053711\n",
      "Epoch 2920 loss 7.4123358726501465\n",
      "Epoch 2940 loss 7.359306812286377\n",
      "Epoch 2960 loss 7.307342052459717\n",
      "Epoch 2980 loss 7.256365776062012\n",
      "Epoch 3000 loss 7.206296920776367\n",
      "Epoch 3020 loss 7.157062530517578\n",
      "Epoch 3040 loss 7.108591556549072\n",
      "Epoch 3060 loss 7.06082010269165\n",
      "Epoch 3080 loss 7.013683795928955\n",
      "Epoch 3100 loss 6.9671196937561035\n",
      "Epoch 3120 loss 6.92106819152832\n",
      "Epoch 3140 loss 6.875481128692627\n",
      "Epoch 3160 loss 6.830294609069824\n",
      "Epoch 3180 loss 6.785461902618408\n",
      "Epoch 3200 loss 6.740957736968994\n",
      "Epoch 3220 loss 7.896678924560547\n",
      "Epoch 3240 loss 7.1159138679504395\n",
      "Epoch 3260 loss 6.64845609664917\n",
      "Epoch 3280 loss 6.636558532714844\n",
      "Epoch 3300 loss 6.561500072479248\n",
      "Epoch 3320 loss 6.515449523925781\n",
      "Epoch 3340 loss 6.472758769989014\n",
      "Epoch 3360 loss 6.430553913116455\n",
      "Epoch 3380 loss 6.41576623916626\n",
      "Epoch 3400 loss 10.904799461364746\n",
      "Epoch 3420 loss 6.688903331756592\n",
      "Epoch 3440 loss 6.3726372718811035\n",
      "Epoch 3460 loss 6.276378631591797\n",
      "Epoch 3480 loss 6.22268533706665\n",
      "Epoch 3500 loss 6.179378032684326\n",
      "Epoch 3520 loss 6.240511894226074\n",
      "Epoch 3540 loss 6.781925678253174\n",
      "Epoch 3560 loss 6.423088073730469\n",
      "Epoch 3580 loss 6.1248250007629395\n",
      "Epoch 3600 loss 6.023329257965088\n",
      "Epoch 3620 loss 5.975742340087891\n",
      "Epoch 3640 loss 6.520241737365723\n",
      "Epoch 3660 loss 7.283146858215332\n",
      "Epoch 3680 loss 6.239161491394043\n",
      "Epoch 3700 loss 5.871289253234863\n",
      "Epoch 3720 loss 5.817434310913086\n",
      "Epoch 3740 loss 5.958408355712891\n",
      "Epoch 3760 loss 5.911205291748047\n",
      "Epoch 3780 loss 6.058965682983398\n",
      "Epoch 3800 loss 5.742894172668457\n",
      "Epoch 3820 loss 5.667815208435059\n",
      "Epoch 3840 loss 5.799907207489014\n",
      "Epoch 3860 loss 6.214976787567139\n",
      "Epoch 3880 loss 5.765295505523682\n",
      "Epoch 3900 loss 5.5633463859558105\n",
      "Epoch 3920 loss 5.5130133628845215\n",
      "Epoch 3940 loss 5.830537796020508\n",
      "Epoch 3960 loss 8.532126426696777\n",
      "Epoch 3980 loss 5.827322483062744\n",
      "Epoch 4000 loss 5.485942363739014\n",
      "Epoch 4020 loss 5.383280277252197\n",
      "Epoch 4040 loss 5.337075233459473\n",
      "Epoch 4060 loss 15.461307525634766\n",
      "Epoch 4080 loss 6.281518936157227\n",
      "Epoch 4100 loss 5.377033710479736\n",
      "Epoch 4120 loss 5.269904613494873\n",
      "Epoch 4140 loss 5.198782920837402\n",
      "Epoch 4160 loss 5.750898361206055\n",
      "Epoch 4180 loss 10.746490478515625\n",
      "Epoch 4200 loss 5.616945266723633\n",
      "Epoch 4220 loss 5.287498474121094\n",
      "Epoch 4240 loss 5.1530961990356445\n",
      "Epoch 4260 loss 5.082427024841309\n",
      "Epoch 4280 loss 5.018646717071533\n",
      "Epoch 4300 loss 15.06286907196045\n",
      "Epoch 4320 loss 7.389465808868408\n",
      "Epoch 4340 loss 5.439935207366943\n",
      "Epoch 4360 loss 5.027716636657715\n",
      "Epoch 4380 loss 4.961243152618408\n",
      "Epoch 4400 loss 4.885850429534912\n",
      "Epoch 4420 loss 5.03824520111084\n",
      "Epoch 4440 loss 7.808643817901611\n",
      "Epoch 4460 loss 5.399502277374268\n",
      "Epoch 4480 loss 4.947758674621582\n",
      "Epoch 4500 loss 4.8610100746154785\n",
      "Epoch 4520 loss 4.783469200134277\n",
      "Epoch 4540 loss 4.704708576202393\n",
      "Epoch 4560 loss 19.033588409423828\n",
      "Epoch 4580 loss 5.197134017944336\n",
      "Epoch 4600 loss 5.1055803298950195\n",
      "Epoch 4620 loss 4.802260875701904\n",
      "Epoch 4640 loss 4.696434497833252\n",
      "Epoch 4660 loss 4.612189769744873\n",
      "Epoch 4680 loss 4.539511680603027\n",
      "Epoch 4700 loss 9.875249862670898\n",
      "Epoch 4720 loss 5.491796016693115\n",
      "Epoch 4740 loss 4.812774181365967\n",
      "Epoch 4760 loss 4.643266201019287\n",
      "Epoch 4780 loss 4.54258918762207\n",
      "Epoch 4800 loss 4.449361801147461\n",
      "Epoch 4820 loss 6.575554847717285\n",
      "Epoch 4840 loss 7.748743534088135\n",
      "Epoch 4860 loss 4.783076763153076\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4880 loss 4.604948997497559\n",
      "Epoch 4900 loss 4.447574138641357\n",
      "Epoch 4920 loss 4.345611572265625\n",
      "Epoch 4940 loss 4.76536226272583\n",
      "Epoch 4960 loss 4.551626205444336\n",
      "Epoch 4980 loss 4.85233736038208\n",
      "Epoch 5000 loss 4.509410858154297\n",
      "Epoch 5020 loss 4.383975028991699\n",
      "Epoch 5040 loss 4.273469924926758\n",
      "Epoch 5060 loss 4.1581621170043945\n",
      "Epoch 5080 loss 20.455598831176758\n",
      "Epoch 5100 loss 7.521164894104004\n",
      "Epoch 5120 loss 5.541675090789795\n",
      "Epoch 5140 loss 4.507322788238525\n",
      "Epoch 5160 loss 4.347100734710693\n",
      "Epoch 5180 loss 4.1989545822143555\n",
      "Epoch 5200 loss 4.0757293701171875\n",
      "Epoch 5220 loss 5.371237754821777\n",
      "Epoch 5240 loss 7.750829696655273\n",
      "Epoch 5260 loss 4.429446697235107\n",
      "Epoch 5280 loss 4.261926174163818\n",
      "Epoch 5300 loss 4.141222953796387\n",
      "Epoch 5320 loss 4.004079818725586\n",
      "Epoch 5340 loss 3.878096580505371\n",
      "Epoch 5360 loss 15.577343940734863\n",
      "Epoch 5380 loss 5.616039276123047\n",
      "Epoch 5400 loss 4.273740291595459\n",
      "Epoch 5420 loss 4.203038215637207\n",
      "Epoch 5440 loss 4.032170295715332\n",
      "Epoch 5460 loss 3.867509365081787\n",
      "Epoch 5480 loss 3.759073495864868\n",
      "Epoch 5500 loss 9.74167251586914\n",
      "Epoch 5520 loss 9.168930053710938\n",
      "Epoch 5540 loss 5.246752738952637\n",
      "Epoch 5560 loss 4.338928699493408\n",
      "Epoch 5580 loss 4.11965799331665\n",
      "Epoch 5600 loss 3.982250690460205\n",
      "Epoch 5620 loss 3.8383476734161377\n",
      "Epoch 5640 loss 3.673342227935791\n",
      "Epoch 5660 loss 3.48148250579834\n",
      "Epoch 5680 loss 30.366863250732422\n",
      "Epoch 5700 loss 4.483481407165527\n",
      "Epoch 5720 loss 4.03049373626709\n",
      "Epoch 5740 loss 3.9628067016601562\n",
      "Epoch 5760 loss 3.7465243339538574\n",
      "Epoch 5780 loss 3.5549702644348145\n",
      "Epoch 5800 loss 3.44205904006958\n",
      "Epoch 5820 loss 7.6917853355407715\n",
      "Epoch 5840 loss 3.88395357131958\n",
      "Epoch 5860 loss 3.8178601264953613\n",
      "Epoch 5880 loss 3.6132678985595703\n",
      "Epoch 5900 loss 3.3815667629241943\n",
      "Epoch 5920 loss 5.691784858703613\n",
      "Epoch 5940 loss 4.187097072601318\n",
      "Epoch 5960 loss 3.6927506923675537\n",
      "Epoch 5980 loss 3.5462594032287598\n",
      "Epoch 6000 loss 3.2981133460998535\n",
      "Epoch 6020 loss 3.2864203453063965\n",
      "Epoch 6040 loss 4.26984977722168\n",
      "Epoch 6060 loss 3.8818695545196533\n",
      "Epoch 6080 loss 3.45715594291687\n",
      "Epoch 6100 loss 3.1882011890411377\n",
      "Epoch 6120 loss 2.9069347381591797\n",
      "Epoch 6140 loss 266.9383850097656\n",
      "Epoch 6160 loss 90.65545654296875\n",
      "Epoch 6180 loss 7.629371643066406\n",
      "Epoch 6200 loss 6.925529479980469\n",
      "Epoch 6220 loss 4.979340076446533\n",
      "Epoch 6240 loss 4.507227897644043\n",
      "Epoch 6260 loss 4.362550258636475\n",
      "Epoch 6280 loss 4.261160850524902\n",
      "Epoch 6300 loss 4.168710708618164\n",
      "Epoch 6320 loss 4.074851036071777\n",
      "Epoch 6340 loss 3.9753429889678955\n",
      "Epoch 6360 loss 3.8674914836883545\n",
      "Epoch 6380 loss 3.7492692470550537\n",
      "Epoch 6400 loss 3.618924140930176\n",
      "Epoch 6420 loss 3.4750161170959473\n",
      "Epoch 6440 loss 3.3164944648742676\n",
      "Epoch 6460 loss 3.142852544784546\n",
      "Epoch 6480 loss 2.95426607131958\n",
      "Epoch 6500 loss 2.7517573833465576\n",
      "Epoch 6520 loss 2.5373053550720215\n",
      "Epoch 6540 loss 2.313944101333618\n",
      "Epoch 6560 loss 2.0856828689575195\n",
      "Epoch 6580 loss 1.8572417497634888\n",
      "Epoch 6600 loss 1295.79638671875\n",
      "Epoch 6620 loss 467.6278991699219\n",
      "Epoch 6640 loss 28.360715866088867\n",
      "Epoch 6660 loss 18.94190216064453\n",
      "Epoch 6680 loss 17.087919235229492\n",
      "Epoch 6700 loss 16.60362434387207\n",
      "Epoch 6720 loss 16.102224349975586\n",
      "Epoch 6740 loss 15.620621681213379\n",
      "Epoch 6760 loss 15.140921592712402\n",
      "Epoch 6780 loss 14.659743309020996\n",
      "Epoch 6800 loss 14.175228118896484\n",
      "Epoch 6820 loss 13.686036109924316\n",
      "Epoch 6840 loss 13.191065788269043\n",
      "Epoch 6860 loss 12.68941879272461\n",
      "Epoch 6880 loss 12.180441856384277\n",
      "Epoch 6900 loss 11.663727760314941\n",
      "Epoch 6920 loss 11.13918399810791\n",
      "Epoch 6940 loss 10.607078552246094\n",
      "Epoch 6960 loss 10.068134307861328\n",
      "Epoch 6980 loss 9.523599624633789\n",
      "Epoch 7000 loss 8.975343704223633\n",
      "Epoch 7020 loss 8.425891876220703\n",
      "Epoch 7040 loss 7.878479480743408\n",
      "Epoch 7060 loss 7.336943626403809\n",
      "Epoch 7080 loss 6.805567741394043\n",
      "Epoch 7100 loss 6.288778781890869\n",
      "Epoch 7120 loss 5.79075288772583\n",
      "Epoch 7140 loss 5.314993381500244\n",
      "Epoch 7160 loss 4.863955020904541\n",
      "Epoch 7180 loss 4.438788890838623\n",
      "Epoch 7200 loss 4.03928804397583\n",
      "Epoch 7220 loss 3.664006233215332\n",
      "Epoch 7240 loss 3.3105151653289795\n",
      "Epoch 7260 loss 2.9757742881774902\n",
      "Epoch 7280 loss 2.656545400619507\n",
      "Epoch 7300 loss 2.3498687744140625\n",
      "Epoch 7320 loss 2.0536305904388428\n",
      "Epoch 7340 loss 1.767236351966858\n",
      "Epoch 7360 loss 1.4922683238983154\n",
      "Epoch 7380 loss 1.2328550815582275\n",
      "Epoch 7400 loss 0.9952667951583862\n",
      "Epoch 7420 loss 0.7865293025970459\n",
      "Epoch 7440 loss 0.692266583442688\n",
      "Epoch 7460 loss 1630.5924072265625\n",
      "Epoch 7480 loss 72.91666412353516\n",
      "Epoch 7500 loss 38.81171417236328\n",
      "Epoch 7520 loss 26.415937423706055\n",
      "Epoch 7540 loss 22.190622329711914\n",
      "Epoch 7560 loss 21.89841651916504\n",
      "Epoch 7580 loss 21.626638412475586\n",
      "Epoch 7600 loss 21.39107894897461\n",
      "Epoch 7620 loss 21.16230583190918\n",
      "Epoch 7640 loss 20.93467903137207\n",
      "Epoch 7660 loss 20.70789909362793\n",
      "Epoch 7680 loss 20.481550216674805\n",
      "Epoch 7700 loss 20.255361557006836\n",
      "Epoch 7720 loss 20.02910614013672\n",
      "Epoch 7740 loss 19.802566528320312\n",
      "Epoch 7760 loss 19.575571060180664\n",
      "Epoch 7780 loss 19.347970962524414\n",
      "Epoch 7800 loss 19.119625091552734\n",
      "Epoch 7820 loss 18.89041519165039\n",
      "Epoch 7840 loss 18.660236358642578\n",
      "Epoch 7860 loss 18.428997039794922\n",
      "Epoch 7880 loss 18.196624755859375\n",
      "Epoch 7900 loss 17.963035583496094\n",
      "Epoch 7920 loss 17.728185653686523\n",
      "Epoch 7940 loss 17.492008209228516\n",
      "Epoch 7960 loss 17.25446128845215\n",
      "Epoch 7980 loss 17.015499114990234\n",
      "Epoch 8000 loss 16.77509307861328\n",
      "Epoch 8020 loss 16.533206939697266\n",
      "Epoch 8040 loss 16.28981590270996\n",
      "Epoch 8060 loss 16.04489517211914\n",
      "Epoch 8080 loss 15.798423767089844\n",
      "Epoch 8100 loss 15.550387382507324\n",
      "Epoch 8120 loss 15.30077838897705\n",
      "Epoch 8140 loss 15.04958438873291\n",
      "Epoch 8160 loss 14.796799659729004\n",
      "Epoch 8180 loss 14.542425155639648\n",
      "Epoch 8200 loss 14.286462783813477\n",
      "Epoch 8220 loss 14.02892017364502\n",
      "Epoch 8240 loss 13.769801139831543\n",
      "Epoch 8260 loss 13.509132385253906\n",
      "Epoch 8280 loss 13.246928215026855\n",
      "Epoch 8300 loss 12.983220100402832\n",
      "Epoch 8320 loss 12.718042373657227\n",
      "Epoch 8340 loss 12.451433181762695\n",
      "Epoch 8360 loss 12.183444023132324\n",
      "Epoch 8380 loss 11.914135932922363\n",
      "Epoch 8400 loss 11.64357852935791\n",
      "Epoch 8420 loss 11.371855735778809\n",
      "Epoch 8440 loss 11.099059104919434\n",
      "Epoch 8460 loss 10.825301170349121\n",
      "Epoch 8480 loss 10.550701141357422\n",
      "Epoch 8500 loss 10.275405883789062\n",
      "Epoch 8520 loss 9.999578475952148\n",
      "Epoch 8540 loss 9.723387718200684\n",
      "Epoch 8560 loss 9.447039604187012\n",
      "Epoch 8580 loss 9.170751571655273\n",
      "Epoch 8600 loss 8.894768714904785\n",
      "Epoch 8620 loss 8.619348526000977\n",
      "Epoch 8640 loss 8.344779968261719\n",
      "Epoch 8660 loss 8.071355819702148\n",
      "Epoch 8680 loss 7.799407958984375\n",
      "Epoch 8700 loss 7.529259204864502\n",
      "Epoch 8720 loss 7.261257648468018\n",
      "Epoch 8740 loss 6.995757102966309\n",
      "Epoch 8760 loss 6.733104705810547\n",
      "Epoch 8780 loss 6.473649024963379\n",
      "Epoch 8800 loss 6.217729091644287\n",
      "Epoch 8820 loss 5.9656572341918945\n",
      "Epoch 8840 loss 5.717720985412598\n",
      "Epoch 8860 loss 5.474182605743408\n",
      "Epoch 8880 loss 5.235255241394043\n",
      "Epoch 8900 loss 5.001108169555664\n",
      "Epoch 8920 loss 4.771859169006348\n",
      "Epoch 8940 loss 4.547564506530762\n",
      "Epoch 8960 loss 4.328221321105957\n",
      "Epoch 8980 loss 4.113759994506836\n",
      "Epoch 9000 loss 3.904052257537842\n",
      "Epoch 9020 loss 3.6988956928253174\n",
      "Epoch 9040 loss 3.498025417327881\n",
      "Epoch 9060 loss 3.3011112213134766\n",
      "Epoch 9080 loss 3.1077654361724854\n",
      "Epoch 9100 loss 2.917543649673462\n",
      "Epoch 9120 loss 2.729954719543457\n",
      "Epoch 9140 loss 2.5444746017456055\n",
      "Epoch 9160 loss 2.360563039779663\n",
      "Epoch 9180 loss 2.177699327468872\n",
      "Epoch 9200 loss 1.9954187870025635\n",
      "Epoch 9220 loss 1.8134105205535889\n",
      "Epoch 9240 loss 1.6316040754318237\n",
      "Epoch 9260 loss 1.4503440856933594\n",
      "Epoch 9280 loss 1.2705937623977661\n",
      "Epoch 9300 loss 1.0941722393035889\n",
      "Epoch 9320 loss 0.923930287361145\n",
      "Epoch 9340 loss 0.7637546062469482\n",
      "Epoch 9360 loss 0.6181895136833191\n",
      "Epoch 9380 loss 0.4915759265422821\n",
      "Epoch 9400 loss 0.3868989646434784\n",
      "Epoch 9420 loss 0.30486053228378296\n",
      "Epoch 9440 loss 0.2437104433774948\n",
      "Epoch 9460 loss 0.19995495676994324\n",
      "Epoch 9480 loss 0.16947931051254272\n",
      "Epoch 9500 loss 0.14849737286567688\n",
      "Epoch 9520 loss 0.134019136428833\n",
      "Epoch 9540 loss 0.12494157999753952\n",
      "Epoch 9560 loss 8.91059398651123\n",
      "Epoch 9580 loss 4.6395134925842285\n",
      "Epoch 9600 loss 0.9957060813903809\n",
      "Epoch 9620 loss 0.461180716753006\n",
      "Epoch 9640 loss 0.28800493478775024\n",
      "Epoch 9660 loss 0.23042942583560944\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9680 loss 0.18693424761295319\n",
      "Epoch 9700 loss 0.15877874195575714\n",
      "Epoch 9720 loss 0.1398165225982666\n",
      "Epoch 9740 loss 0.12775765359401703\n",
      "Epoch 9760 loss 7.229023456573486\n",
      "Epoch 9780 loss 0.5038362741470337\n",
      "Epoch 9800 loss 0.49900731444358826\n",
      "Epoch 9820 loss 0.38363397121429443\n",
      "Epoch 9840 loss 0.28987008333206177\n",
      "Epoch 9860 loss 0.2286674976348877\n",
      "Epoch 9880 loss 0.18409492075443268\n",
      "Epoch 9900 loss 0.15539385378360748\n",
      "Epoch 9920 loss 0.13658998906612396\n",
      "Epoch 9940 loss 1.8949702978134155\n",
      "Epoch 9960 loss 2.232023000717163\n",
      "Epoch 9980 loss 0.5184746384620667\n"
     ]
    }
   ],
   "source": [
    "\n",
    "with tf.Session() as session:\n",
    "        \n",
    "    session.run(tf.global_variables_initializer())\n",
    "        \n",
    "    for epoch in range(EPOCHS):\n",
    "        _  = session.run(adam_optimize,feed_dict={X:x,Y:y})\n",
    "            \n",
    "        if epoch % PRINT_EVERY == 0:\n",
    "            batch_loss = session.run(loss,feed_dict={X:x,Y:y})\n",
    "            print(\"Epoch {} loss {}\".format(epoch,batch_loss))\n",
    "                \n",
    "    \n",
    "    test_predictions,test_loss = session.run([nalu2_output,loss],feed_dict={X:test_x,Y:test_y})\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.00088167],\n",
       "       [ 0.00115616],\n",
       "       [ 0.00021493],\n",
       "       ..., \n",
       "       [ 0.00034554],\n",
       "       [ 0.00030776],\n",
       "       [ 0.00060215]], dtype=float32)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 517.46103106],\n",
       "       [ 488.65691363],\n",
       "       [ 547.22592468],\n",
       "       ..., \n",
       "       [ 535.47099587],\n",
       "       [ 555.33736389],\n",
       "       [ 520.43096886]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "251126.42"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Why am i getting this  big test error and different scale? papers claims 0.0 error in a+ b task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
